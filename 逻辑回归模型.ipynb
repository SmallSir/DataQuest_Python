{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets,linear_model,discriminant_analysis\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据\n",
    "def load_data():\n",
    "    iris = datasets.load_iris()\n",
    "    x_train = iris.data\n",
    "    y_train = iris.target\n",
    "    return train_test_split(x_train,y_train,test_size = 0.25,random_state = 0,stratify = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用库实现逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LogisticRegression(*data):\n",
    "    x_train,x_test,y_train,y_test = data\n",
    "    regr = linear_model.LogisticRegression()\n",
    "    regr.fit(x_train,y_train)\n",
    "    print('Coefficients: %s, intercept %s'%(regr.coef_,regr.intercept_))\n",
    "    print('Score: %.2f'%regr.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[ 0.39310895  1.35470406 -2.12308303 -0.96477916]\n",
      " [ 0.22462128 -1.34888898  0.60067997 -1.24122398]\n",
      " [-1.50918214 -1.29436177  2.14150484  2.2961458 ]], intercept [ 0.24122458  1.13775782 -1.09418724]\n",
      "Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = load_data()\n",
    "test_LogisticRegression(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逻辑回归模型参数\n",
    "#### penalty指定正则化策略，l1或者l2\n",
    "#### dual返回true为求解对偶形式\n",
    "#### C指定罚项系数的倒数，越小正则化项越大\n",
    "#### fit_intercept指定是否需要计算b值\n",
    "#### max_iter迭代次数\n",
    "#### solver最优化问题的算法 'newton-cg'牛顿法，'lbfgs'L-BFGS拟牛顿法，‘liblinear’使用liblinear，‘sag’使用一个啊啊啊算法,小数据用liblinear，大数据集用sag\n",
    "#### tol判断迭代收敛与否的阀值\n",
    "#### multi_class表示对多分类问题的策略，'ovr'采用one-vs-rest策略,'multinomial'直接采用多分类逻辑回归策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi_class参数对分类结果的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LogisticRegression_multinomial(*data):\n",
    "    x_train,x_test,y_train,y_test = data\n",
    "    regr = linear_model.LogisticRegression(multi_class='multinomial',solver = 'lbfgs')\n",
    "    regr.fit(x_train,y_train)\n",
    "    print('Coefficients: %s, intercept %s'%(regr.coef_,regr.intercept_))\n",
    "    print('Score: %.2f'%regr.score(x_test,y_test))\n",
    "#该策略只能使用牛顿的求解最优化问题的算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[-0.38365872  0.85501328 -2.27224244 -0.98486171]\n",
      " [ 0.34359409 -0.37367647 -0.03043553 -0.86135577]\n",
      " [ 0.04006464 -0.48133681  2.30267797  1.84621747]], intercept [  8.79984878   2.46853199 -11.26838077]\n",
      "Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = load_data()\n",
    "test_LogisticRegression_multinomial(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对于参数C来说，随着C增大，准确率在上升，当C增大到一定程度，准确度保持不变"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码实现逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归损失函数 cost = -ylog(p)- (1-y)log(1-p) 当y=1或0，p = 1/(1 + e ^(-X * seita))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(t):#逻辑回归公式\n",
    "    return 1./ (1 + np.exp(-t))\n",
    "def fit_gd(self, X_train, y_train, eta=0.01, n_iters=1e4):\n",
    "        \"\"\"根据训练数据集X_train, y_train, 使用梯度下降法训练Linear Regression模型\"\"\"\n",
    "        assert X_train.shape[0] == y_train.shape[0], \\\n",
    "            \"the size of X_train must be equal to the size of y_train\"\n",
    "\n",
    "        def J(theta, X_b, y):#每一行的误差和\n",
    "            y_hat = _sigmoid(x_b.dot(theta))\n",
    "            try:\n",
    "                return - np.sum(y*np.log(y_hat)+ (1 - y)*np.log(1 - y_hat))/len(y)\n",
    "            except:\n",
    "                return float('inf')\n",
    "\n",
    "        def dJ(theta, X_b, y):#返回的是每个参数误差\n",
    "            return X_b.T.dot(_sigmoid(x_b.dot(theta))- y) / len(X_b)\n",
    "\n",
    "        def gradient_descent(X_b, y, initial_theta, eta, n_iters=1e4, epsilon=1e-8):\n",
    "\n",
    "            theta = initial_theta\n",
    "            cur_iter = 0\n",
    "\n",
    "            while cur_iter < n_iters:\n",
    "                gradient = dJ(theta, X_b, y)\n",
    "                last_theta = theta\n",
    "                theta = theta - eta * gradient\n",
    "                if (abs(J(theta, X_b, y) - J(last_theta, X_b, y)) < epsilon):\n",
    "                    break\n",
    "\n",
    "                cur_iter += 1\n",
    "\n",
    "            return theta\n",
    "\n",
    "        X_b = np.hstack([np.ones((len(X_train), 1)), X_train])\n",
    "        initial_theta = np.zeros(X_b.shape[1])\n",
    "        self._theta = gradient_descent(X_b, y_train, initial_theta, eta, n_iters)\n",
    "\n",
    "        self.intercept_ = self._theta[0]\n",
    "        self.coef_ = self._theta[1:]\n",
    "\n",
    "        return self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
